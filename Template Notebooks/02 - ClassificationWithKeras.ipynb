{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" width=\"120\" src=\"https://s3.eu-west-1.amazonaws.com/neueda.conygre.com/pydata/images/neueda-logo.jpeg\">\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this version of the notebook has many empty cells.\n",
    "\n",
    "Try to complete the cells as you go to explore the functionality and behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a model to predict the total dollar amount that customers are willing to pay given the following attributes: \n",
    "- Customer Name\n",
    "- Customer e-mail\n",
    "- Country\n",
    "- Gender\n",
    "- Age\n",
    "- Annual Salary \n",
    "- Credit Card Debt \n",
    "- Net Worth \n",
    "\n",
    "The model should predict: \n",
    "- Car Purchase Amount "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the python packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = pd.read_excel('https://s3.eu-west-1.amazonaws.com/neueda.conygre.com/pydata/ml_intro/DL_DATA.xls',\n",
    "                        sheet_name = 'CARS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cars.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: we could use sns.pairplot or pandas.plotting.scatter_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training and Test Data\n",
    "\n",
    ">\n",
    ">**X** - Matrix of independent variables (inputs)\n",
    ">\n",
    ">**y** - Dependent variable vector (outputs)\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted columns\n",
    "\n",
    "# TODO: let's drop 'Customer Name, email, country and car purchase amount' and assign the result to X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the `Gender` column\n",
    "\n",
    ">\n",
    ">`M` ==> 0\n",
    ">\n",
    ">`F` ==> 1\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# we'll one-hot encode the text from the gender column\n",
    "preprocessor = make_column_transformer( (OneHotEncoder(categories='auto'),[0]),remainder=\"passthrough\")\n",
    "X['Gender'] = preprocessor.fit_transform(X)[:,0]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set y to be the Car Purchase Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Use `MinMaxScaler` to scale/normalize model to values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# TODO: create a MinMaxScaler and fit it to X\n",
    "# then use this scaler to transform X into X_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the max for each column in the X MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the min for each column in the X MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll make y a 500x1 numpy array so it's ready for a MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As above, we'll also scale y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Test and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the scikit learn train_test_split utility\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "Useing Keras to build the network \n",
    "- Sequentially (from left to right)\n",
    "- Dense - all outputs are fully connected to next layer(hidden)\n",
    "\n",
    "**Dense**\n",
    "- input_dim - how many inputs (age, gender, etc)\n",
    "- units - how many neurons in the first layer\n",
    "- activation - rulu, sigmoid etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# create a keras Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# First Hidden Layer - 5 input features\n",
    "\n",
    "\n",
    "# Additional Hidden Layer - no need to specify input_dim here, Keras figures this out\n",
    "\n",
    "\n",
    "# Third Hidden Layer\n",
    "\n",
    "# Specify the output (units = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a summary of the current structure of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model, we'll use the adam optimizer and mean_squared_error loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (fit) the model\n",
    "\n",
    "Vary the `epochs` and `batch_size` parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "# set some parameters e.g.: epochs=40, batch_size=10 verbose=1 validation_data=(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras gives us log information from each epoch\n",
    "print(epochs_hist.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can plot this info to see how we performed during the training process\n",
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.plot(epochs_hist.history['val_loss'])\n",
    "\n",
    "plt.title('Model Loss Progression During Training/Validation')\n",
    "plt.ylabel('Training and Validation Losses')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend(['Training Loss', 'Validation Loss']);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction - we need to scale again!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale a numpy array of Gender, Age, Annual Salary, Credit Card Debt, Net Worth\n",
    "X_Testing = np.array([[1, 50, 94500, 20000, 5000]])\n",
    "\n",
    "# TODO: transform with our X_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the model predict for these features?\n",
    "\n",
    "\n",
    "# remember to \"unscale\" with y_scaler!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale the entire test X data and then get the model to predict results\n",
    "\n",
    "# we'll \"unscale\" each time with the y_scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot actual vs predicted - for perfect predictions this would be a straight line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we could produce a table with the error for each datapoint, allowing for further analysis of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({'y_test_pred': pd.Series(y_test_pred.ravel()), 'y_test_actual': pd.Series(y_test_actual.ravel())})\n",
    "result_df['error'] = result_df['y_test_pred'] - result_df['y_test_actual']\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vary the hyper parameters\n",
    "\n",
    "We could now begin to vary the number of neurons and check the performance and the time taken to train the network\n",
    "\n",
    "Question: if we do this, then are there consequences for the validity of our test data set?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
